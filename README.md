Docker Proteus Environment
=========
This repository contains the Docker multi-container application to deploy the Proteus Environment and manage the dataset.

Getting started
---------------

1. Download and install [Docker](https://www.docker.com).
2. Download and install [Docker Compose](https://docs.docker.com/compose/install/).

Running Proteus Environment
---------------

Use the Docker Proteus Environment is very easy. You only have to download the repository, copy the dataset in the propertly folder and execute the proteus-environment.sh script. To accomplish the first step, you have to download the repository with the commands:
```{r, engine='bash', count_lines}
git clone https://github.com/proteus-h2020/proteus-docker.git
cd proteus-docker
```

Into proteus-docker folder, you will find a repository called proteus-data with a empty folder hsm into them. This is where you have to put all the data that you want to manage in. To launch the Proteus Docker Environment, execute de shell script

```{r, engine='bash', count_lines}
./proteus-environment.sh
```

If the Docker daemon is running propertly, you will see the follow menu:

1. Install Proteus Environment
2. Check conatiners
3. Stop Containers
4. Delete Containers
5. Unistall Proteus Environment


You only have to select your favorite option and let Docker make all the hard work. The options offered by the Proteus Environment Menu are:

Proteus Environment menu
---------

1. Install Proteus Environment:
⋅⋅⋅This option will pull all the images and setup all the containers in the correct order from scratch.

2. Check status:
⋅⋅⋅This option will print the state of all the containers. The same as dockers ps -a

3. Stop all continers:
⋅⋅⋅Stop and remove all the containers. Free the memory.

4. Remove all containers:
⋅⋅⋅Stop and delete all the containers.

5. Unistall Proteus Environment:
⋅⋅⋅This option will delete all the containers and images used by Docker to running-up the Proteus Environment.

Architecture
-----
Docker Proteus Environment have one container based on the lightweight image of Alpine Linux for each service:

* Name Node
  * WebUI http://namenode:50070
* Resource Manager
  * WebUI http://resourcemanager:8088
* Data Node 1
* Data Node 2
* Data Node 3
* Node Manager 1
* Node Manager 2
* Node Manager 3
* Kafka
* Zookeeper

We don´t have the IPs of the containers on our hosts file, so we have to access by the IP. All the containers are in a VPN generated by Docker so if you need to know the IP of a container you can use the command:
```{r, engine='bash', count_lines}
sudo docker inspect container-name
```
This command will prompt all the info about the container configuration and you only have to finde the container IP.

Finally, if you need to access to a container and make changes you can use the command:
```{r, engine='bash', count_lines}
sudo docker exec -it container-name bash
```
You may need to restart the container with the docker commands.


Future Work
-----------

* Integrate Apache Flink
* Integrate Apache Hive

Note
---------------
This environmente it is build on Alpine Linux images and inspired in other GitHub proyects:
 
* Hive [big-data-europe/docker-hive](https://github.com/big-data-europe/docker-hive)
* Hadoop [big-data-europe/docker-hadoop](https://github.com/big-data-europe/docker-hadoop)
